{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5JUaviI0ida"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint, time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FLO2WqS0k5G",
        "outputId": "bb5cfbcf-bad5-4ddb-c041-6b1c7f8a8526"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "<ipython-input-2-1fee6b514c45>:14: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  test_accuracy = hmm_tagger.evaluate(test_data)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:332: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.37\n"
          ]
        }
      ],
      "source": [
        "#import nltk\n",
        "nltk.download('treebank')\n",
        "# Load the Penn Treebank dataset\n",
        "corpus = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_data = corpus[:3000]\n",
        "test_data = corpus[3000:]\n",
        "\n",
        "# Train an HMM POS tagger\n",
        "hmm_tagger = nltk.hmm.HiddenMarkovModelTrainer().train_supervised(train_data)\n",
        "\n",
        "# Evaluate the tagger on the test data\n",
        "test_accuracy = hmm_tagger.evaluate(test_data)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_Ns2vh0nj8"
      },
      "outputs": [],
      "source": [
        "def pos_tag(sentence, tagger):\n",
        "    tokens = nltk.tokenize.word_tokenize(sentence)\n",
        "    tagged = tagger.tag(tokens)\n",
        "    return tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LSqFM_V0uzo",
        "outputId": "ec7f9d4a-3333-40b4-9c7d-d6bf7b99d80e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOfEUzjB0vXU",
        "outputId": "b63c7038-e540-4aa0-a239-75c9f693dab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the sentence to tag: i love swimming\n",
            "[('i', 'NNP'), ('love', 'NNP'), ('swimming', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "user_input = input(\"Enter the sentence to tag: \")\n",
        "print(pos_tag(user_input, hmm_tagger))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GziEg-67bkWc",
        "outputId": "ea8201a5-763f-43da-9b22-34bdb0edd2ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence: nagpur is the capital of india\n",
            "POS tags:\n",
            "nagpur: PRP\n",
            "is: VBZ\n",
            "the: DT\n",
            "capital: NN\n",
            "of: IN\n",
            "india: DT\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import HiddenMarkovModelTrainer\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "# Take user input\n",
        "user_input = input(\"Enter a sentence: \")\n",
        "\n",
        "# Tokenize the input text into words\n",
        "words = word_tokenize(user_input)\n",
        "\n",
        "# Initialize training data with tagged sentences (you can use a larger tagged corpus for better results)\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "# Initialize the HMM trainer\n",
        "trainer = HiddenMarkovModelTrainer()\n",
        "\n",
        "# Train the HMM model on the tagged sentences with log probabilities enabled\n",
        "model = trainer.train_supervised(tagged_sentences, estimator=lambda fd, bins: nltk.LidstoneProbDist(fd, 0.1, bins))\n",
        "\n",
        "# Perform POS tagging using the trained HMM model\n",
        "pos_tags = model.tag(words)\n",
        "\n",
        "# Print the POS tags for each word\n",
        "print(\"POS tags:\")\n",
        "for word, pos_tag in pos_tags:\n",
        "    print(f\"{word}: {pos_tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "# Load the Penn Treebank dataset\n",
        "corpus = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_data = corpus[:3000]\n",
        "test_data = corpus[3000:]\n",
        "\n",
        "# Train an HMM POS tagger\n",
        "hmm_tagger = nltk.hmm.HiddenMarkovModelTrainer().train_supervised(train_data)\n",
        "\n",
        "# Evaluate the tagger on the test data\n",
        "test_accuracy = hmm_tagger.evaluate(test_data)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3mwhCAxbkzU"
      },
      "outputs": [],
      "source": [
        "lookup tables \n",
        "transition probabilities: how likely a noun is followed by a model which is followed by a verb and then a  noun \n",
        " and emission probability : how likely jae will be a noun or  will be a modal\n",
        "\n",
        "draw a table in which emission probability is taken into consideration \n",
        "how many time mary came as noun , as modal or as verb \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
